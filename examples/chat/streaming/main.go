// Example: Streaming Chat Completion
//
// This example demonstrates how to use streaming responses
// to display text as it's generated by the model.
//
// Run with:
//
//	export OPENAI_API_KEY=your-key
//	go run main.go
package main

import (
	"context"
	"fmt"
	"os"
	"time"

	"github.com/petal-labs/iris/core"
	"github.com/petal-labs/iris/providers/openai"
)

func main() {
	apiKey := os.Getenv("OPENAI_API_KEY")
	if apiKey == "" {
		fmt.Fprintln(os.Stderr, "OPENAI_API_KEY environment variable not set")
		os.Exit(1)
	}

	provider := openai.New(apiKey)
	client := core.NewClient(provider)

	ctx, cancel := context.WithTimeout(context.Background(), 60*time.Second)
	defer cancel()

	fmt.Println("Streaming response:")
	fmt.Println("---")

	// Start streaming request
	stream, err := client.Chat("gpt-4o-mini").
		User("Write a short poem about programming in Go. Make it 4 lines.").
		Stream(ctx)

	if err != nil {
		fmt.Fprintln(os.Stderr, "Error starting stream:", err)
		os.Exit(1)
	}

	// Print chunks as they arrive
	for chunk := range stream.Ch {
		fmt.Print(chunk.Delta)
	}
	fmt.Println()
	fmt.Println("---")

	// Check for any errors during streaming
	select {
	case err := <-stream.Err:
		if err != nil {
			fmt.Fprintln(os.Stderr, "Stream error:", err)
			os.Exit(1)
		}
	default:
	}

	// Get final response with usage stats
	select {
	case resp := <-stream.Final:
		if resp != nil {
			fmt.Printf("Tokens: %d prompt + %d completion = %d total\n",
				resp.Usage.PromptTokens,
				resp.Usage.CompletionTokens,
				resp.Usage.TotalTokens)
		}
	default:
		fmt.Println("(Usage stats not available)")
	}
}
